# ETL Pipeline Documentation

## ğŸ”„ Vue d'ensemble

Le pipeline ETL (Extract, Transform, Load) est la couche intermÃ©diaire entre le scraper et la base de donnÃ©es PostgreSQL. Il assure le traitement, la validation et le chargement des donnÃ©es immobiliÃ¨res scrapÃ©es.

## ğŸ“‹ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚     SCRAPER     â”‚â”€â”€â”€â–¶â”‚   ETL PIPELINE  â”‚â”€â”€â”€â–¶â”‚   POSTGRESQL    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚                 â”‚
                       â”‚   ETL API       â”‚
                       â”‚   (FastAPI)     â”‚
                       â”‚                 â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants principaux

1. **DataExtractor** - Extraction des donnÃ©es depuis les fichiers JSON
2. **DataTransformer** - Transformation et nettoyage des donnÃ©es
3. **DataValidator** - Validation et contrÃ´le qualitÃ©
4. **PostgreSQLLoader** - Chargement vers PostgreSQL avec support spatial
5. **ETLOrchestrator** - Orchestration du pipeline complet
6. **ScraperETLAdapter** - Interface avec le scraper
7. **ETL API** - Service web pour dÃ©clencher et monitorer l'ETL

## ğŸš€ Utilisation

### Commandes Make disponibles

```bash
# Pipeline complet (Extract + Transform + Load)
make etl-full

# Seulement transformation
make etl-transform

# Seulement chargement
make etl-load

# Scraper + ETL combinÃ©
make scrape-and-etl

# API ETL
make etl-api

# Validation du pipeline
make etl-validate

# Status et rapports
make etl-status
```

### Utilisation directe

```bash
# Pipeline complet
docker-compose run --rm etl python etl/orchestrator.py --full

# Pipeline partiel
docker-compose run --rm etl python etl/orchestrator.py --transform-only
docker-compose run --rm etl python etl/orchestrator.py --load-only

# Avec scraper intÃ©grÃ©
docker-compose run --rm etl python etl/scraper_adapter.py --where Montreal --what condo

# Validation
docker-compose run --rm etl python etl/validate.py
```

## ğŸ“Š FonctionnalitÃ©s

### Extraction
- Lecture des donnÃ©es JSON du scraper
- Support multi-fichiers
- Gestion des erreurs de format

### Transformation
- **Nettoyage des prix** : Conversion "$450,000" â†’ 450000
- **Normalisation des surfaces** : "900 sq ft" â†’ 900
- **Extraction coordonnÃ©es** : GÃ©ocodage des adresses
- **DÃ©duplication** : Hash-based sur titre + localisation
- **Validation des types** : ContrÃ´le de cohÃ©rence

### Chargement
- **PostgreSQL + PostGIS** : Support des donnÃ©es spatiales
- **Upsert intelligent** : Mise Ã  jour ou insertion
- **Indexation automatique** : Index sur localisation et prix
- **Triggers** : Mise Ã  jour automatique des timestamps
- **Transactions** : Rollback en cas d'erreur

### API Web
- **Endpoints RESTful** : DÃ©clenchement Ã  distance
- **Jobs en arriÃ¨re-plan** : ExÃ©cution asynchrone
- **Monitoring** : Status et progression
- **Rapports JSON** : Statistiques dÃ©taillÃ©es

## ğŸ“ Structure des fichiers

```
etl/
â”œâ”€â”€ __init__.py          # Pipeline principal (Extract, Transform, Load)
â”œâ”€â”€ loader.py            # Chargeur PostgreSQL + PostGIS
â”œâ”€â”€ orchestrator.py      # Orchestrateur avec CLI
â”œâ”€â”€ scraper_adapter.py   # Interface scraper
â”œâ”€â”€ api.py              # Service web FastAPI
â”œâ”€â”€ utils.py            # Utilitaires et logging
â”œâ”€â”€ validate.py         # Script de validation
â””â”€â”€ README.md           # Cette documentation
```

## ğŸ”§ Configuration

### Variables d'environnement

```bash
# Base de donnÃ©es
POSTGRES_HOST=postgres
POSTGRES_DB=real_estate
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# ETL
ETL_BATCH_SIZE=100
ETL_LOG_LEVEL=INFO
ETL_DATA_PATH=/app/data
```

### Fichiers de configuration

- **docker-compose.yml** : Service ETL configurÃ©
- **Dockerfile.etl** : Container ETL avec dÃ©pendances
- **.env** : Variables d'environnement

## ğŸ“ˆ Monitoring et Rapports

### Rapports gÃ©nÃ©rÃ©s

1. **etl_report.json** - Rapport phase individuelle
2. **etl_full_report.json** - Rapport pipeline complet
3. **etl_validation_report.json** - Rapport de validation

### Structure des rapports

```json
{
  "phase": "full_pipeline",
  "timestamp": "2024-01-15T10:30:00",
  "duration_seconds": 45.2,
  "success": true,
  "stats": {
    "extracted_records": 150,
    "transformed_records": 148,
    "loaded_records": 148,
    "deduplicated": 2,
    "quality_score": 95.3
  },
  "errors": []
}
```

## ğŸ§ª Tests et Validation

### Validation complÃ¨te
```bash
make etl-validate
```

### Tests individuels
```bash
# Test extraction
docker-compose run --rm etl python etl/validate.py --component extraction

# Test qualitÃ© donnÃ©es
docker-compose run --rm etl python etl/validate.py --component quality

# Test connexion DB
docker-compose run --rm etl python etl/validate.py --component database

# Test composants ETL
docker-compose run --rm etl python etl/validate.py --component etl
```

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

1. **Erreur de connexion DB**
   ```bash
   # VÃ©rifier que PostgreSQL est dÃ©marrÃ©
   make db-status
   
   # RedÃ©marrer si nÃ©cessaire
   make db-restart
   ```

2. **DonnÃ©es manquantes**
   ```bash
   # VÃ©rifier les donnÃ©es source
   ls -la data/scraped_data.json
   
   # Lancer le scraper
   make scrape-test
   ```

3. **Erreurs de transformation**
   ```bash
   # Voir les logs
   docker-compose logs etl
   
   # Validation des donnÃ©es
   make etl-validate
   ```

### Logs

```bash
# Logs du service ETL
docker-compose logs -f etl

# Logs dans le container
docker-compose exec etl tail -f /app/logs/etl.log
```

## ğŸ”’ SÃ©curitÃ©

- **Validation des entrÃ©es** : PrÃ©vention injection SQL
- **Transactions** : AtomicitÃ© des opÃ©rations
- **Logging sÃ©curisÃ©** : Pas de donnÃ©es sensibles dans les logs
- **Variables d'environnement** : Credentials sÃ©curisÃ©s

## ğŸ“ API Reference

### Endpoints principaux

- `POST /etl/run` - Lancer pipeline complet
- `POST /etl/extract` - Extraction uniquement  
- `POST /etl/transform` - Transformation uniquement
- `POST /etl/load` - Chargement uniquement
- `GET /etl/status/{job_id}` - Status d'un job
- `GET /etl/reports` - Liste des rapports
- `GET /health` - Health check

### Exemple d'utilisation API

```bash
# Lancer ETL complet
curl -X POST http://localhost:8788/etl/run \
  -H "Content-Type: application/json" \
  -d '{"source_file": "scraped_data.json"}'

# VÃ©rifier le status
curl http://localhost:8788/etl/status/job-123
```

## ğŸ¯ Performance

### Optimisations

- **Batch processing** : Traitement par lots
- **Index database** : RequÃªtes optimisÃ©es
- **Memory management** : Gestion efficace de la RAM
- **Async processing** : Jobs non-bloquants

### MÃ©triques typiques

- **Extraction** : ~1000 records/seconde
- **Transformation** : ~500 records/seconde  
- **Chargement** : ~200 records/seconde
- **Pipeline complet** : ~150 records/seconde

## ğŸ“š Ressources

- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [PostGIS Spatial Database](https://postgis.net/documentation/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Docker Compose](https://docs.docker.com/compose/)

---

**Note** : Cette documentation couvre la version actuelle du pipeline ETL. Pour les mises Ã  jour, consultez le CHANGELOG.md du projet.
