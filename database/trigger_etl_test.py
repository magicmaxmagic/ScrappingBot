#!/usr/bin/env python3
"""
Script pour dÃ©clencher le pipeline ETL avec des donnÃ©es de test
Permet de tester l'ensemble du flux : scraping -> ETL -> base de donnÃ©es
"""

import asyncio
import requests
import json
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

async def trigger_etl_pipeline():
    """DÃ©clenche le pipeline ETL via l'API"""
    
    # 1. GÃ©nÃ©rer des donnÃ©es de test
    logger.info("ğŸ”„ GÃ©nÃ©ration de donnÃ©es de test...")
    
    # Importer et exÃ©cuter le gÃ©nÃ©rateur
    import sys
    sys.path.append(str(Path(__file__).parent))
    
    from test_data_generator import TestDataGenerator
    
    generator = TestDataGenerator()
    test_listings = generator.generate_batch(count=20)
    
    # Sauvegarder dans le format attendu par l'ETL
    logs_dir = Path(__file__).parent.parent / "logs"
    logs_dir.mkdir(exist_ok=True)
    
    test_file = logs_dir / "preview_realtor.json"
    
    data = {
        "success": True,
        "count": len(test_listings),
        "strategy": "test_data",
        "blocked": False,
        "timestamp": "2025-08-15T19:30:00Z",
        "listings": test_listings
    }
    
    with open(test_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"âœ… DonnÃ©es de test crÃ©Ã©es : {test_file}")
    
    # 2. DÃ©clencher l'ETL via l'API
    logger.info("ğŸš€ DÃ©clenchement du pipeline ETL...")
    
    try:
        # Appel Ã  l'API ETL pour traiter les donnÃ©es
        response = requests.post(
            "http://localhost:8788/etl/full",
            json={
                "input_file": "preview_realtor.json"
            },
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… ETL traitement rÃ©ussi : {result}")
            return result
        else:
            logger.error(f"âŒ Erreur ETL : {response.status_code} - {response.text}")
            return None
                    
    except Exception as e:
        logger.error(f"âŒ Erreur lors de l'appel ETL : {e}")
        return None

async def check_database_content():
    """VÃ©rifie le contenu de la base de donnÃ©es aprÃ¨s ETL"""
    try:
        import asyncpg
        
        conn = await asyncpg.connect(
            host="localhost",
            port=5432,
            database="scrappingbot",
            user="scrappingbot_user",
            password="scrappingbot_pass"
        )
        
        # Compter les enregistrements
        listings_count = await conn.fetchval("SELECT COUNT(*) FROM listings")
        areas_count = await conn.fetchval("SELECT COUNT(*) FROM areas")
        metrics_count = await conn.fetchval("SELECT COUNT(*) FROM area_metrics")
        logs_count = await conn.fetchval("SELECT COUNT(*) FROM scrape_logs")
        
        logger.info(f"ğŸ“Š Contenu de la base de donnÃ©es :")
        logger.info(f"  - Listings : {listings_count}")
        logger.info(f"  - Areas : {areas_count}")  
        logger.info(f"  - Area metrics : {metrics_count}")
        logger.info(f"  - Scrape logs : {logs_count}")
        
        # Afficher quelques exemples
        if listings_count > 0:
            sample_listings = await conn.fetch(
                "SELECT address, price, bedrooms, bathrooms FROM listings LIMIT 3"
            )
            logger.info("ğŸ“‹ Exemples d'annonces :")
            for listing in sample_listings:
                logger.info(f"  - {listing['address']} - ${listing['price']:,} - {listing['bedrooms']}BR/{listing['bathrooms']}BA")
        
        await conn.close()
        return {
            "listings": listings_count,
            "areas": areas_count,
            "metrics": metrics_count,
            "logs": logs_count
        }
        
    except Exception as e:
        logger.error(f"âŒ Erreur vÃ©rification base : {e}")
        return None

async def main():
    """Point d'entrÃ©e principal"""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    logger.info("ğŸš€ DÃ©marrage du test du pipeline ETL")
    
    # 1. DÃ©clencher ETL avec donnÃ©es de test
    etl_result = await trigger_etl_pipeline()
    
    if etl_result:
        logger.info("âœ… Pipeline ETL exÃ©cutÃ© avec succÃ¨s")
        
        # 2. VÃ©rifier le contenu de la base
        logger.info("ğŸ” VÃ©rification du contenu de la base de donnÃ©es...")
        await asyncio.sleep(2)  # Laisser le temps Ã  l'ETL de finir
        
        db_content = await check_database_content()
        
        if db_content and db_content["listings"] > 0:
            logger.info("ğŸ‰ SuccÃ¨s ! Les donnÃ©es sont maintenant en base de donnÃ©es")
        else:
            logger.warning("âš ï¸  Aucune donnÃ©e trouvÃ©e en base - vÃ©rifiez les logs ETL")
    else:
        logger.error("âŒ Ã‰chec du pipeline ETL")

if __name__ == "__main__":
    asyncio.run(main())
